
```{r}
source('RECURSOS-INVESTIGACION/R/get-dat-basic-normalizada.R')
source('RECURSOS-INVESTIGACION/R/pef-r2-ids-eeff-forecast.R')
source('RECURSOS-INVESTIGACION/R/pef-list-summary-resumen.R')
source('RECURSOS-INVESTIGACION/R/pef-get-dats-for-forescat.R')
source('RECURSOS-INVESTIGACION/R/pef-get-ids-for-models.R')
source("RECURSOS-INVESTIGACION/R/pef-get-camel-test.R")
source("RECURSOS-INVESTIGACION/R/pef-aux-render-table.R")
source("RECURSOS-INVESTIGACION/R/render-table-basic.R")

require(kableExtra)
require(patchwork)
require(ggplot2)
require(dplyr)
require(fpp2)

if (!('listResultPEF' %in% ls())) {
    
    datTotalSistema <- getDatEEFFNormalizada(by = 'TOTAL_SISTEMA')
    
    ids <- getVariablesForModelsForecast()
    
    listResultPEF <- getListFittedAndSimulateModels(datTotalSistema,ids)
    listResumeModels <- getListResumeSummaryModels(listResultPEF)
    listDatsForTestCamels <- getDatsForTestCamels(listResultPEF,datTotalSistema,12,TRUE)
    
    
    originalCamelTest <- getCamelTestForecast(listDatsForTestCamels$datCuentas)
    nnCamelTest <- getCamelTestForecast(listDatsForTestCamels$nnDataForecastCuentas)
    mcoCamelTest <- getCamelTestForecast(listDatsForTestCamels$mcoDataForecastCuentas)
    arimaCamelTest <- getCamelTestForecast(listDatsForTestCamels$arimaDataForecastCuentas)
    
    camelTestModels <- bind_rows(originalCamelTest,
                                 nnCamelTest,
                                 mcoCamelTest,
                                 arimaCamelTest)
    
    id <- 'EERR_S2_RESULTADO_NETO_DE_LA_GESTION'
    
    trendCamelRNN <- readRDS(file ='FUENTES-DE-DATOS/DATA/trendCamelRNN.rds')
    sdCamelRNN <- readRDS(file ='FUENTES-DE-DATOS/DATA/sdCamelRNN.rds')
}

```


## Evaluación de datos ajustados de modelos

En esta sección se presentan el nivel de ajuste de los modelos para las distintas series de tiempo observadas respecto a las series de tiempo pronosticadas por los modelos:

```{r}
renderTableBasic(listResumeModels$r2ModelsResum %>% transformTableAuxPef, 
                 captionTable = 'Ajuste R2 por cuentas',
                 fontSize = 6)
```

Donde el ajuste promedio por modelo se tiene los siguiente:

```{r}
renderTableBasic(listResumeModels$r2ModelsResumMean, 
                 captionTable = 'Ajuste R2 por modelos',
                 fontSize = 6)
```

Dejando a las redes neuronales como el mejor modelo bajo el presente método de evaluación al tener mayor ajuste promedio para las diferentes series de tiempo.

## Evaluación de datos proyectados de modelos

Ahora bien, se presenta el nivel de ajuste de las proyecciones de los modelos respecto a las series de tiempo de prueba, las cuales no fueron incluidas en el entrenamiento de los mismos.

```{r}
renderTableBasic(listResumeModels$r2ForecastResum %>% transformTableAuxPef, 
                 captionTable = 'Ajuste R2 de proyecciones por cuentas',
                 fontSize = 6) %>% 
    footnote(general = 'NaN indica que uno de los series de tiempo es 0 en todos sus elementos, donde el R2 devuelve una indeterminación.',
             general_title = 'NOTA: ' )
```

Donde el ajuste promedio de las proyecciones por modelo se tiene los siguiente:

```{r}
renderTableBasic(listResumeModels$r2ForecastResumMean,
                 captionTable = 'Ajuste R2 de proyecciones por modelo',
                 fontSize = 6)
```

En el segundo método de evaluación los modelos ARIMA lograron mayor ajuste R2 en las series de tiempo proyectadas, lo que entra en contradicción con la evaluación anterior para poder resolver esta contradicción el siguiente método no evaluara el ajuste de los modelos sino su capacidad de generalizar los patrones contenidos en las series de tiempo sobre los cuales en ultimo termino se pueden tomar decisiones.


